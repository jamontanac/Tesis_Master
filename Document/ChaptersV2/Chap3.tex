\chapter{Getting to understand Ultra Orthogonality in the $XY$ Model.}

As discussed in the previous chapters, we are interested in solvable Fermionic systems. Indeed the one dimensional $XY$ model is one of those systems\cite{lieb_two_1961}. The XY Hamiltonian model is a set of $N$ spin $1/2$ particles 
located on the sites of d-dimensional lattice. Nevertheless, whenever we talk about the $XY$ model, we will be referring to the $1D$ $XY$ model.
\section{The $XY$ Model}
A chain of $N$ spins where each spin is able to interact with its nearest neighbours in the $X$ and $Y$ coordinate as well as an external magnetic field, will be described by the Hamiltonian of the form
\begin{equation}
H_{X Y}=-\frac{1}{2} \sum_{l=0}^{N-1}\left(\frac{1+\gamma}{2} \sigma_{l}^{x} \sigma_{l+1}^{x}+\frac{1-\gamma}{2} \sigma_{l}^{y} \sigma_{l+1}^{y}+\lambda \sigma_{l}^{z}\right),
\label{CH3:Hamiltonian_XY}
\end{equation}
where $\gamma$ is so-called the anisotropy parameter and represents the difference between the strength of the $XX$ interaction and the $YY$ interaction\footnote{When we talk about interactions we mean interactions between spins.}, $\lambda$ is the intensity of the external magnetic field and $\sigma^{i}_{l}$ is the Pauli matrix ($i= x,y,z$) acting over the $l$ site of the chain.\\
The XY model is a model that has been widely studied for a variety of values of $\lambda$ and $\gamma$ and in some limits it has a correspondence to other models of interest in condensed matter\cite{katsura_statistical_1962,barouch_statistical_1971,barouch_statistical_1970}\footnote{Some examples of this kind, are the Boson Hubbard model in the limit of hard Bosons. the case when $\gamma=1$ correspond to the Ising model, and the Kitaev chain is equivalent to the XY model under a proper identification of the parameters $\mu$, $t$ and $\Delta$ with $\gamma$ and $\lambda$\cite{katsura_statistical_1962,barouch_statistical_1971}}.
\subsection{The spectrum}
To find the spectrum of the Hamiltonian \eqref{CH3:Hamiltonian_XY} we need to perform some special transformations.
\subsection{Jordan-Wigner Transformation}
We first consider the non local transformation given by
\begin{equation}
\hat{b}_{l}=\left(\prod_{m<l} \sigma_{m}^{z}\right) \sigma_{l}^{-}, \quad \sigma_{l}^{-}=\frac{\sigma_{l}^{x}-i \sigma_{l}^{y}}{2},
\end{equation}
where these $b_l$ represent spinless Fermionic operators, and its canonical anticommutation relation (CAR) is given by\cite{reyes-lega_aspects_2016} 
\begin{equation}
\left\{\hat{b}_{i}^{\dagger}, \hat{b}_{j}^{\dagger}\right\}=\left\{\hat{b}_{i}, \hat{b}_{j}\right\}=0, \quad\left\{\hat{b}_{i}^{\dagger}, \hat{b}_{j}\right\}=\delta_{i, j}.
\end{equation}
So inverting the transformation we get 
\begin{equation}
\begin{array}{l}
\sigma_{l}^{z}=1-2 \hat{b}_{l}^{\dagger} \hat{b}_{l} \\
\sigma_{l}^{x}=\left(\prod_{m<l}\left(1-2 \hat{b}_{m}^{\dagger} \hat{b}_{m}\right)\right)\left(\hat{b}_{l}^{\dagger}+\hat{b}_{l}\right) \\
\sigma_{l}^{y}=i\left(\prod_{m<l}\left(1-2 \hat{b}_{m}^{\dagger} \hat{b}_{m}\right)\right)\left(\hat{b}_{l}^{\dagger}-\hat{b}_{l}\right).
\end{array}
\end{equation}

The terms of interaction in the Hamiltonian will look as
\begin{equation}
\begin{aligned}
\hat{\sigma}_{l}^{x} \hat{\sigma}_{l+1}^{x} &=\left(\hat{b}_{l}^{\dagger}-\hat{b}_{l}\right)\left(\hat{b}_{l+1}^{\dagger}+\hat{b}_{l+1}\right) \\
\hat{\sigma}_{l}^{y} \hat{\sigma}_{l+1}^{y} &=-\left(\hat{b}_{l}^{\dagger}+\hat{b}_{l}\right)\left(\hat{b}_{l+1}^{\dagger}-\hat{b}_{l+1}\right),
\end{aligned}
\end{equation}
and the Hamiltonian will look like,
\begin{equation}
H_{X Y}=-\frac{1}{2} \sum_{l}\left[\left(\hat{b}_{l+1}^{\dagger} \hat{b}_{l}+\hat{b}_{l}^{\dagger} \hat{b}_{l+1}\right)+\gamma\left(\hat{b}_{l}^{\dagger} \hat{b}_{l+1}^{\dagger}-\hat{b}_{l} \hat{b}_{l+1}\right)\right]-\frac{\lambda}{2} \sum_{l}\left(1-2 \hat{b}_{l}^{\dagger} \hat{b}_{l}\right),
\end{equation}
after this transformation. The term of $-\lambda N/2$ is usually ignored since it cause only a gauge of the spectrum in the energy\cite{reyes-lega_aspects_2016} .
\subsection{Fourier Transformation}
It is possible to exploit an other symmetry in the system. It comes by considering periodic boundary conditions (PBC)\cite{reyes-lega_aspects_2016} . This can be easily done by identifying the spin in the site $N$ with the spin in the site $1$. After imposing this condition, we have that the Fourier transform of the operator $\hat{b}_l$ will look as
\begin{equation}
\hat{d}_{k}=\frac{1}{\sqrt{N}} \sum_{l=1}^{N} \hat{b}_{l} e^{-i \phi_{k} l},
\end{equation}
with $\theta_{k}=\frac{2 \pi}{N} k$.\\
Since the Fourier transformation is unitary, the operators $\hat{d}_k$ will preserve the CAR.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{Figures/Periodic_boundaries.png}
    \caption{Illustration of what a boundary condition means in the case of our spin chain.}
    \label{periodic condition}
\end{figure}
Thus, the Hamiltonian can be written in terms of the operators $\hat{d}_k$ as
\begin{equation}
H_{X Y}=\sum_{k=-(N-1) / 2}^{(N-1) / 2}\left(-\lambda+\cos \phi_{k}\right) \hat{d}_{k}^{\dagger} \hat{d}_{k}+\frac{i \gamma}{2} \sum_{k=-(N-1) / 2}^{(N-1) / 2} \sin \phi_{k}\left(\hat{d}_{k} \hat{d}_{-k}+h . c\right),
\end{equation}
where we have ignored an additional term which is proportional to $1/N$ which will vanish for in the thermodynamic limit $N\to \infty$\cite{barouch_statistical_1970,barouch_statistical_1971}, which is our case of interest.
\subsection{Bogoliubov -Valantin Transformation}
As mentioned before Fermionic quadratic Hamiltonians can be easily diagonalised via a Bogoliubov-Valantin transformation over the operators $\hat{d}_k$

\begin{equation}
\tilde{d}_{k}=u_{k} \hat{d}_{k}^{\dagger}+i v_{k} \hat{d}_{-k}.
\end{equation}
Since we want this transformation to preserve CAR, it is needed that $u_k^2 + v_k^2 = 1$, which implies that we can use the parametrization $u_{k}=\cos \left(\psi_{k} / 2\right)$ and $v_{k}=\sin \left(\psi_{k} / 2\right)$, with
\begin{equation}
\cos \frac{\psi_{k}}{2}=\frac{-\lambda+\cos \phi_{k}}{\sqrt{\left(\lambda-\cos \phi_{k}\right)^{2}+\left(\gamma \sin \phi_{k}\right)^{2}}},
\end{equation}
So finally our Hamiltonian will look as
\begin{equation}
H_{X Y}=\sum_{-(N-1) / 2}^{(N-1) / 2} \tilde{\Lambda}_{k} \tilde{d}_{k}^{\dagger} \tilde{d}_{k},
\end{equation}
with 
\begin{equation}
\tilde{\Lambda}_{k}:=\sqrt{\left(\lambda-\cos \phi_{k}\right)^{2}+\left(\gamma \sin \phi_{k}\right)^{2}},
\label{CH3:Spectrum_XY_model}
\end{equation}
where the latter expression allow us to identify the critical regions of the model.
\subsection{Fermionic Covariance Matrix for the XY model}

As we mentioned before, sometimes it turns out to be better, and useful to work directly with the Covariance matrix. To be able to do so, we need to express the Hamiltonian \eqref{CH3:Hamiltonian_XY} in terms of Majoranana fermions. This can be done by using an analogous of the Jordan Wigner transformation use to diagonalised the XY Hamiltonian but now we apply it to the $2N$ Majorana fermions

\begin{equation}
\hat{\gamma}_{l}=\left(\prod_{m<l} \hat{\sigma}_{m}^{z}\right) \hat{\sigma}_{l}^{x}, \quad \hat{\gamma}_{l+N}=\left(\prod_{m<l} \hat{\sigma}_{m}^{z}\right) \hat{\sigma}_{l}^{y},
\end{equation}
where again $l=1,2\ldots N-1$,
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Figures/ecuacion.png}
    \caption{Illustration of how the spins in the chain are mapped to the Majorana fermions.}
    \label{majorana fermions}
\end{figure}
and similarly as before we have that
\begin{equation}
\hat{\gamma}_{l} \hat{\gamma}_{l+N}=\left(\prod_{m<l} \hat{\sigma}_{m}^{z}\right)\left(\prod_{m<l} \hat{\sigma}_{m}^{z}\right) \hat{\sigma}_{l}^{x} \hat{\sigma}_{l}^{y}=i \hat{\sigma}_{l}^{z},
\end{equation}
\begin{equation}
\hat{\gamma}_{l+N} \hat{\gamma}_{l+1}=\left(\prod_{m<l} \hat{\sigma}_{m}^{z}\right) \hat{\sigma}_{l}^{y}\left(\prod_{m<l+1} \hat{\sigma}_{m}^{z}\right) \hat{\sigma}_{l+1}^{x}=\hat{\sigma}_{l}^{y} \hat{\sigma}_{l}^{z} \hat{\sigma}_{l+1}^{x}=i \hat{\sigma}_{l}^{x} \hat{\sigma}_{l+1}^{x},
\end{equation}
\begin{equation}
\hat{\gamma}_{l} \hat{\gamma}_{l+N+1}=\left(\prod_{m<l} \hat{\sigma}_{m}^{z}\right) \hat{\sigma}_{l}^{x}\left(\prod_{m<l+1} \hat{\sigma}_{m}^{z}\right) \hat{\sigma}_{l+1}^{y}=\hat{\sigma}_{l}^{x} \hat{\sigma}_{l}^{z} \hat{\sigma}_{l+1}^{y}=-i \hat{\sigma}_{l}^{y} \hat{\sigma}_{l+1}^{y}.
\end{equation}
Which coincide, up to constant factors, with the three terms in the Hamiltonian \eqref{CH3:Hamiltonian_XY}. This will lead us to a Hamiltonian of the form\cite{botero_bcs-like_2004,latorre_ground_2004}
\begin{equation}
H_{X Y}=\frac{i}{4} \sum_{\alpha, \beta=0}^{2 N} \Omega_{\alpha \beta}\left[\hat{\gamma}_{\alpha}, \hat{\gamma}_{\beta}\right],
\label{CH3:Hamiltonian_to_diagonalise}
\end{equation}
where $\Omega$ is the antisymmetric matrix of the form
\begin{equation}
\Omega=\left[\begin{array}{c|c}
0 & \tilde{\Omega} \\
\hline -\tilde{\Omega}^{T} & 0
\end{array}\right],
\label{CH3:Block_matrix}
\end{equation}
with 
\begin{equation}
\tilde{\Omega}=\begin{pmatrix}
\lambda & \frac{1-\gamma}{2} & 0 &0 &\ldots  &0 &\frac{1+\gamma}{2}\\
\frac{1+\gamma}{2} & \lambda & \frac{1-\gamma}{2} & 0 &\ldots &0 &0\\
0 & \frac{1+\gamma}{2} & \lambda & \frac{1-\gamma}{2} &\ldots &0 &0\\
\vdots& \ddots & \ddots & \ddots & \ldots &  \vdots & \vdots\\
\frac{1-\gamma}{2}&0&0&0&\ldots & \frac{1+\gamma}{2} & \lambda.
\end{pmatrix}.
\label{CH3:Hamiltonian_matrix_XY_model}
\end{equation}
In general \eqref{CH3:Block_matrix} can be diagonalised via an orthogonal transformation $O$\cite{botero_bcs-like_2004,latorre_ground_2004} \footnote{This special relation provide us a way to transform from spacial modes to excitation in the chain, so that we can either excite the chain and see what the spatial modes are or the other way.}
\begin{equation}
    \Omega=O\left[\begin{array}{c|c}
0 & \omega \\
\hline \omega & 0
\end{array}\right] O^T,
\label{CH3:Matrix_decomposed}
\end{equation}
where $O\in O(2N)$.  Writing it in terms of two smaller orthogonal matrices will look as
\begin{equation}
O=\left[\begin{array}{c|c}
O_1 & 0 \\
\hline 0 & O_2
\end{array}\right],
\end{equation}
and $\omega$ is a diagonal matrix of size $N\times N$ which holds excitation numbers $-1/2+n$. By doing the product of matrices in \eqref{CH3:Matrix_decomposed} we can easily see that 
\begin{equation}
    \tilde{\Omega}=O_1 \omega O_2^T,
\end{equation}
which is nothing but the singular value decomposition of the matrix $\tilde{\Omega}$. The latter result tell us that a fast way to construct the matrix $O$, which diagonalise $\Omega$, is to focus on $\tilde{\Omega}$.
\newline
A fact that we can exploit is that , the matrix described in equation \eqref{CH3:Hamiltonian_matrix_XY_model} $\tilde{\Omega}$ is a circulant real matrix, meaning that it can be easily diagonalised by means of a Fourier transform. So we can write
\begin{equation}
\tilde{\Omega}_{m n}=\frac{1}{N} \sum_{\theta_{k} \in(-\pi, \pi)} \omega\left(\theta_{k}\right) e^{\phi\left(\theta_{k}\right)} e^{i(m-n) \theta_{k}}.
\label{CH3:circulant_expantion}
\end{equation}
where $\omega\left(\theta_{k}\right)=\omega\left(\theta_{k}\right)^{*}=\omega\left(-\theta_{k}\right), \phi\left(\theta_{k}\right)=-\phi\left(\theta_{k}\right)$ and are given by
\begin{equation}
\omega^{2}\left(\theta_{k}\right):=\left(\lambda-\cos \theta_{k}\right)^{2}+\gamma^{2} \sin ^{2} \theta_{k},
\end{equation}
and
\begin{equation}
\phi\left(\theta_{k}\right):=\arctan \left(\frac{\lambda-\cos \theta_{k}}{-\gamma \sin \theta_{k}}\right).
\end{equation}
So expanding the equation \eqref{CH3:circulant_expantion}, we get
\begin{equation}
\begin{aligned}
\tilde{\Omega}_{m n} &=\frac{1}{N}\left[\omega(0)+(-1)^{m-n} \omega(\pi)+2 \sum_{0<\theta_{k}<\pi} \omega\left(\theta_{k}\right) \cos \left(\theta_{k}(m-n)+\phi\left(\theta_{k}\right)\right)\right] \\
&=\frac{\omega(0)}{N}+(-1)^{m-n} \frac{\omega(\pi)}{N}+\sum_{0<\theta_{k} \leq \pi} \omega\left(\theta_{k}\right)\left(u_{m}^{c}\left(\theta_{k}\right) v_{n}^{c}\left(\theta_{k}\right)+u_{m}^{s}\left(\theta_{k}\right) v_{n}^{s}\left(\theta_{k}\right)\right),
\end{aligned}
\end{equation}

where
\begin{equation}
u_{m}^{c}\left(\theta_{k}\right)=\sqrt{\frac{2}{N}} \cos \left(m \theta_{k}+\phi\left(\theta_{k}\right)\right), \quad u_{m}^{s}\left(\theta_{k}\right)=\sqrt{\frac{2}{N}} \sin \left(m \theta_{k}+\phi\left(\theta_{k}\right)\right),
\end{equation}
\begin{equation}
v_{n}^{c}\left(\theta_{k}\right)=\sqrt{\frac{2}{N}} \cos \left(n \theta_{k}\right), \quad u_{n}^{s}\left(\theta_{k}\right)=\sqrt{\frac{2}{N}} \sin \left(n \theta_{k}\right).
\end{equation}
Now defining $
u^{s}(0)=v^{s}(\pi)=0 \mathrm{y} u^{c}(0)=v^{c}(\pi)=\frac{1}{\sqrt{N}}$, we have that $\tilde{\Omega}_{m,n}$ can be written as
\begin{equation}
\tilde{\Omega}_{m n}=\sum \omega\left(\theta_{k}\right)\left(u_{m}^{c}\left(\theta_{k}\right) v_{n}^{c}\left(\theta_{k}\right)+u_{m}^{s}\left(\theta_{k}\right) v_{n}^{s}\left(\theta_{k}\right)\right).
\end{equation}
Therefore the upper part of the Hamiltonian reads
\begin{equation}
H=\sum_{m, n=0}^{N-1} \frac{i}{4} \sum_{\theta_{k}=0}^{\pi} \omega\left(\theta_{k}\right)\left(u_{m}^{c}\left(\theta_{k}\right) v_{n}^{c}\left(\theta_{k}\right)+u_{m}^{s}\left(\theta_{k}\right) v_{n}^{s}\left(\theta_{k}\right)\right)\left[\hat{\gamma}_{n}, \hat{\gamma}_{m+N}\right],
\end{equation}

\begin{equation}
H=\sum_{\theta_{k}=0}^{\pi} \omega\left(\theta_{k}\right)(\underbrace{\left[\hat{\gamma}_{k}^{c}, \hat{\gamma}_{k+N}^{c}\right]}_{1-2\sigma^{z     }_k}+\underbrace{\left[\hat{\gamma}_{k}^{s}, \hat{\gamma}_{k+N}^{s}\right]}_{1-2\sigma^{z}_k}),
\end{equation}

where
\begin{equation}
\hat{\gamma}_{k}^{c, s}:=\sum_{n} u_{n}^{c, s}\left(\theta_{k}\right) \hat{\gamma}_{n}, \quad \hat{\gamma}_{k+N}^{c, s}:=\sum_{n} v_{n}^{c, s}\left(\theta_{k}\right) \hat{\gamma}_{n+N}.
\end{equation}
Now we look back on the fact that the Fermionic covariance matrix, defined by $
\Gamma_{\alpha \beta}=\frac{1}{2 i} \operatorname{tr}\left(\rho\left[\gamma_{\alpha}, \gamma_{\beta}\right]\right)=\frac{1}{2 i}\langle \left[\gamma_{\alpha}, \gamma_{\beta}\right] \rangle$, that brings $\Omega$ into its Williamson form, does the same on the Fermionic covariance matrix. Thus for a state $|\vec{n}\rangle$, consider an eigenstate of the base $(c,s,\theta_k)$, where $m^{c, s}\left(\theta_{k}\right)-1 / 2$, with $n^{c, s}\left(\theta_{k}\right)$ the occupation number of \textit{cosine}, \textit{sine} in the $k-$mode. We get 

\begin{equation}
\begin{aligned}
\tilde{\Gamma}_{m n} &=\sum_{\theta_{k}}^{\pi}\left[m^{c}\left(\theta_{k}\right) u_{m}^{c}\left(\theta_{k}\right) v_{n}^{c}\left(\theta_{k}\right)+m^{s}\left(\theta_{k}\right) u_{m}^{s}\left(\theta_{k}\right) v_{n}^{s}\left(\theta_{k}\right)\right] \\
&=\sum_{\theta_{k}}^{\pi}\left(\frac{m^{c}\left(\theta_{k}\right)+m^{s}\left(\theta_{k}\right)}{2}\right)\left(u_{m}^{c}\left(\theta_{k}\right) v_{n}^{c}\left(\theta_{k}\right)+u_{m}^{s}\left(\theta_{k}\right) v_{n}^{s}\left(\theta_{k}\right)\right) \\
&+\sum_{\theta_{k}}^{\pi}\left(\frac{m^{c}\left(\theta_{k}\right)-m^{s}\left(\theta_{k}\right)}{2}\right)\left(u_{m}^{c}\left(\theta_{k}\right) v_{n}^{c}\left(\theta_{k}\right)-u_{m}^{s}\left(\theta_{k}\right) v_{n}^{s}\left(\theta_{k}\right)\right).
\end{aligned}
\end{equation}
by defining $m^{\pm}\left(\theta_{k}\right)=\frac{m^{c}\left(\theta_{k}\right) \pm m^{s}\left(\theta_{k}\right)}{2}$ and inverting the transformations done above, we finally get that
\begin{equation}
\tilde{\Gamma}_{m n}=\overbrace{\sum_{\theta_{k}}^{\pi} m^{+}\left(\theta_{k}\right) e^{i \phi\left(\theta_{k}\right)} e^{i(n-m) \theta_{k}}}^{\tilde{\Gamma}^{+}_{mn}}+\underbrace{\sum_{\theta_{k}}^{\pi} m^{-}\left(\theta_{k}\right) e^{i \phi\left(\theta_{k}\right)} e^{i(n+m) \theta_{k}}}_{\tilde{\Gamma}_{m n}^{-}}.
\end{equation}
We notice that $\tilde{\Gamma}^{+}_{mn}$ is circulant, whereas $\tilde{\Gamma}^{-}_{mn}$ is not, nevertheless, observe that $\tilde{\Gamma}^{+}_{mn} = \tilde{\Gamma}^{}_{mn'}$, with $n'$ a change on the index $n\to -n'$, which can be interpreted as a rotation over the circle.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{Figures/Reflection_over_circle.png}
    \caption{Meaning of the relabel done in the circulant matrix, which can be seen as a reflection over the circle.}
    \label{reflectioncircle}
\end{figure}
Explicitly we can write that if $\tilde{\Gamma}^{+}_{mn}$ has the shape
\begin{equation}
\left(\begin{array}{ccccc}
a_{0} & a_{-1} & \cdots & a_{2} & a_{1} \\
a_{1} & a_{0} & \cdots & a_{3} & a_{2} \\
\cdot & \cdot & \cdot & \cdots & \cdot \\
\vdots & \vdots & \vdots & \vdots & \vdots \\
a_{-1} & a_{-2} & a_{-3} & \cdots & a_{0}
\end{array}\right),
\end{equation}
then $\tilde{\Gamma}^{-}_{mn}$ will be given by
\begin{equation}
\left(\begin{array}{ccccc}
a_{0} & a_{1} & \cdots & a_{-2} & a_{-1} \\
a_{1} & a_{2} & \cdots & a_{-1} & a_{0} \\
\cdot & \cdot & \cdot & \cdots & \cdot \\
\vdots & \vdots & \vdots & \vdots & \vdots \\
a_{-1} & a_{0} & a_{1} & \cdots & a_{-2}
\end{array}\right).
\end{equation}

So we can spot 3 things. First, the FCM always can be written as a circulant matrix plus an anticirculant matrix. Second, in the Ground state, the FCM is circulant only, since the fermion occupation numbers $n^{c}\left(\theta_{k}\right)=n^{s}\left(\theta_{k}\right)=0, \forall k$. Third, for a generic state, we have that in average the FCM matrix is always circulant, because $\langle n^{c}\left(\theta_{k}\right)\rangle=\langle n^{s}\left(\theta_{k}\right)\rangle$.\\
Now that we have showed a full characterization of the $XY$ model, we change gears and start to board our main problem. In the next section we are going to show how this is possible to find a bound in the case of the $XY$ model and even more, we will show that the mechanism for Ultra Orthogonality in this system, is indeed related with the structure of the system.


\section{Exploring ``Ultra Orthogonality''}
Now having all the tools we need we can apply what we discussed in section $2$. First we are going to look at the error exponents for the $XY$ model, we will compute the probabilities of having errors and show some numerical results. Then we move to our next problem, we will show for the $XY$ model is possible to bound the determinant and even more we find an analytical result for this determinant based on a generalisation of Szeg\"o limit theorems. 

\subsection{Error exponent}

First we recall the fact that in order to sample states at a given temperature we make use of a very well known technique, named Gibbs sampling. This technique is a special case of a Markov chain Monte Carlo algorithm. Is is well known for obtaining sequences of observations which are approximated from a specified multivariate probability distribution, It is a very useful tool for simulations in Markov processes for which the transition from which transition matrix cannot be formulated explicitly because the state space is too large\cite{robert_multi-stage_2004,gilks_markov_1996,noauthor_gibbs_nodate}. Our goal is then to sample over excited states $\ket{\vec{n}}$, where the occupations $n_q$ will be sampled independently according to the Boltzmann distribution
\begin{equation}
p(\vec{n} \mid \beta)=\prod_{q=0}^{N-1} p\left(n_{q} \mid \beta\right), \quad p\left(n_{q} \mid \beta\right)=\frac{e^{-\beta \epsilon\left(\theta_{q}\right) n_{q}}}{\sum_{n_{q}} e^{-\beta \epsilon\left(\theta_{q}\right) n_{q}}},
\label{CH3:Gibbs_Sampling}
\end{equation}
where we explicitly put the dependence of the energy with certain angle in \eqref{CH3:Gibbs_Sampling} having in mind the case of the $XY$ model\footnote{However, the $XY$ model is not the only model in which the energy can be parametrized in terms of an angle, in general it has been shown that every one-dimentional translationally invariant closed chain of free Fermions/Bosons will have this property \cite{eisert_area_2010,fradkin_field_1997,katsura_statistical_1962,latorre_ground_2004,lieb_two_1961}.}. The goal of using this technique  that the size of the Hilbert space is to find the probability distribution with a given temperature $\beta$. It is well known that in the Fermionic case, the average number of excitations in the mode at angle $\theta$ is given by
\begin{equation}
f\left(\theta_{q} \mid \beta\right) \equiv\left\langle n_{q}\right\rangle_{\beta}=\frac{1}{e^{\beta \epsilon\left(\theta_{q}\right)} + 1},
\end{equation}
while the variance in the number of excitations is given by

\begin{equation}
v\left(\theta_{q} \mid \beta\right) \equiv\left\langle n_{q}^{2}\right\rangle_{\beta}-\left\langle n_{q}\right\rangle_{\beta}^{2}=\frac{1}{e^{\beta \epsilon\left(\theta_{q}\right)} + 1}=f\left(\theta_{q}\right)\left(1 - f\left(\theta_{q}\right)\right).
\end{equation}
With this method of sampling, the mean energy is 
\begin{equation}
\langle E\rangle_{\beta}=\sum_{q} f_{q}\left(\theta_{q} \mid \beta\right) \epsilon_{q}\left(\theta_{q}\right)=N \oint_{N} \frac{d \theta}{2 \pi} f(\theta \mid \beta) \epsilon(\theta),
\end{equation}
where $\oint$ denote the Riemann sum approximation to the respective integral with $N$ subdivisions. As we mentioned before we are interested in the limit $N\to\infty$, we will replace the sums by its correspondent integral. Similarly we can compute the energy variance of the sampled states 
\begin{equation}
\left\langle\Delta E^{2}\right\rangle_{\beta}=\sum_{q} v_{q}\left(\theta_{q} \mid \beta\right) \epsilon_{q}^{2}\left(\theta_{q}\right)=N \oint_{N} \frac{d \theta}{2 \pi} v(\theta \mid \beta) \epsilon^{2}(\theta).
\end{equation}
Thus Gibbs sampling provides an even sampling of states within $\Delta E$ of the energy $\langle E\rangle$, where $\Delta E/\langle E\rangle\sim O(N^{-1/2})$.\\
Thinking back on the case of the $XY$ model, the ensemble defined by Gibbs sampling is nothing but the canonical ensemble defined on the full chain, with thermal density matrix
\begin{equation}
\rho_{T}(\beta, N)=\sum_{\vec{n}} p(\vec{n} \mid \beta)|\vec{n}\rangle\langle\vec{n}|=\frac{e^{-\beta H_{N}}}{Z(\beta, N)}, \quad \log Z(\beta, N)= N  \oint_{N} \frac{d \theta}{2 \pi}\log \left(1 \pm e^{-\beta \epsilon(\theta)}\right).
\end{equation}
This thermal state defines a reduced density matrix in the subchain of length $L$
\begin{equation}
\left.\rho(\beta, N)\right|_{L} \equiv \operatorname{Tr}_{N-L} \rho_{T}(\beta, N),
\end{equation}
which is expected to correspond to the local thermal state,
\begin{equation}
 \left.\rho(\beta, N)\right|_{L} \simeq \rho_{T}(\beta, L) \equiv \frac{e^{-\beta H_{L}}}{Z(\beta, L)},
\end{equation}
 for $L$ sufficiently larger in comparison to the correlation length, in which the boundary effects can be neglected. Since we know this states conserve Gaussianity under partial traces, the reduced state $\left.\rho(\beta, N)\right|_{L}$ will be also Gaussian, meaning that the state will be uniquely characterised by its covariance matrix. This arguments lead us to the conclusion that the Gibbs average of the reduced partial density matrices $\rho_L(\vec{n})$ satisfies
 \begin{equation}
 \left.\rho(\beta, N)\right|_{L}=\left\langle\rho_{L}(\vec{n})\right\rangle_{\beta}.
 \end{equation}
The latter series of arguments where need to understand why this method of sampling is appropriate for our purpose. Even more, it provide us an expression to the probability of having and excitation (a $1$) or not ($0$). Having said that, we move gears to the computing the probability of having an error over two independent sequences. We can write this probability in terms of our energy as and a given $\theta_k$
\begin{equation}
n(\theta_k)=\frac{1}{1+e^{\beta(\Omega(\theta_k)-\Omega^*)}},
\end{equation}
where $\Omega(\theta_k)$ is given by equation \eqref{CH3:Spectrum_XY_model}, and $\Omega^*$ correspond to the minimum of energy\footnote{It is not hard to check that the minimum of energy happens at $\theta^*=\pm \operatorname{acos}\left(-\frac{\lambda}{1-\gamma^2}\right)$ with value
\[\sqrt{\frac{\gamma^2(\gamma^2-1+\lambda^2)}{(\gamma^2-1)}}.\]}. Then the probability of two sequences not having an error in the position $k$ will be given by
\begin{equation}
1-p(\theta_k) = n(\theta_k)^2 + (1-n(\theta_k))^2 = \frac{1}{1+\operatorname{sech}\left(\beta(\Omega(\theta_k)-\Omega^*)\right)},
\end{equation}
and then the probability of having an error will be given by
\begin{equation}
p(\theta_k) = \frac{1}{1+\cosh\left(\beta(\Omega(\theta_k)-\Omega^*)\right)},
\label{CH3:Probability_of_error_in_site_k}
\end{equation}
So the expected value of the number of errors $X=\sum_{k}X(\theta_k)$ is given by

\begin{equation}
\mu = \sum p(\theta_k) \stackrel{N\to \infty}{=}\frac{N}{2\pi}\oint d\theta \frac{1}{1+\cosh{(\beta(\Omega(\theta)-\Omega^*)})}.
   \label{CH3:average_of_errors}
\end{equation}
In Figure \ref{CH3:examples_of_probability_distribution_errors}, we show the behaviour of the probability distribution as a function of the angle. 


\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.47\textwidth}
    \centering
    \includegraphics[width = \textwidth]{Figures/beta_1.png}
    \caption{Probability distributions of errors as a function of the position in the chain. this plot correspond to a value of $\beta=1$.}
    \label{beta1}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.47\textwidth}
    \centering
    \includegraphics[width = \textwidth]{Figures/beta_80.png}
    \caption{Probability distributions of errors as a function of the position in the chain. this plot correspond to a value of $\beta=80$.}
    \label{beta80}
\end{subfigure}
\caption{An illustration of how the probability distribution $p(\theta_k)$ behaves as a function of the angle $\theta$. As we can see in both figures there are regions of the chain in which the probability of having an error is smaller.}
       \label{CH3:examples_of_probability_distribution_errors}
\end{figure}

As we would like to study a little deeper the behaviour of the expected value as a function of the temperature we could take the obtain some expressions for some limit cases.
We can expand \eqref{CH3:average_of_errors} when $\beta\to 0$.

\begin{equation*}
    \mu \approx \frac{N}{2\pi}\left(\frac{2\pi}{2}-\beta^2\int_{-\pi}^{\pi}\frac{(\Omega(\theta)-\Omega^{*})^2}{8}d\theta\right)
\end{equation*}
\begin{equation}
    =\frac{N}{2}-\frac{N\beta^2}{16}\int_{-\pi}^{\pi}(\Omega(\theta)-\Omega^{*})^2d\theta,
    \label{CH3:beta_to_0}
\end{equation}
which means that in the limit of $\beta\to 0$ (High temperatures), the expected value $\mu$ will tend to $N/2$. From other side, if we look at the case when $\beta\to \infty$, the integral \eqref{CH3:average_of_errors} can be approximated as
\begin{equation}
    \mu \to \frac{N}{2\pi}\oint e^{-\beta(\Omega(\theta)-\Omega^{*})}d\theta\to 0,
    \label{CH3:beta_to_infty}
\end{equation}

which is agreement with the fact that at zero temperature, the possible sequences are those which have no excitations, and therefore will have only zeros.\\
We can now compute the error exponent associated with this model by just replacing the probability in \eqref{CH3:Probability_of_error_in_site_k} into the expression found in \eqref{CH2:Error_exponent}, to obtain
\begin{equation}
r(\delta) = \min_{S}\oint \frac{d\theta}{2\pi}\log\left(1+\frac{1}{1+\cosh\left(\beta(\Omega(\theta)-\Omega^*)\right)}(e^S-1)\right)-S\delta.
\label{CH3:Error_exponent_for_xy_model}
\end{equation}
Even though we are not able to find an exact solution to this, we can do a numerical exercise and see how this behaves as a function of the temperature. In figure \ref{CH3:Results_Exponent_error_XY_model} our results are shown.

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.63\textwidth}
    \centering
    \includegraphics[width = \textwidth]{Figures/Error_Exponents.pdf}
    \caption{Error exponent function for the $XY$ model, in the figure the behaviour as a function of $\beta$ is shown. The equation\eqref{CH3:Error_exponent_for_xy_model} is solved for values of $\beta$ running from $0.01$ to $200$}
    \label{error_exponent}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.35\textwidth}
    \centering
    \includegraphics[width = \textwidth]{Figures/Error_Exponents_zoom.pdf}
    \caption{Zoom on the region of lower $\beta$'s. The equation\eqref{CH3:Error_exponent_for_xy_model} is solved for values of $\beta$ running from $0.01$ to $1$}
    \label{error_exponent_zoom}
\end{subfigure}
\caption{Plot of the solution of equation \eqref{CH3:Error_exponent_for_xy_model}, the behaviour of $r(\delta)$ is shown as a function of $\beta$.}
       \label{CH3:Results_Exponent_error_XY_model}
\end{figure}

Now we go back the problem we left behind and start analysing the case when the number of errors is less than $L$.
\subsection{Finding Bounds for $\hat{X}_{ij}$}

In Chapter two we discussed that if we are able to show that the operator $\hat{X}_{ij}$ in norm is small, we could assert that Super Orthogonality will hold. First we want to find a bound to this quantity in terms of the transformations $\mathcal{U}$ and $\mathcal{V}$. As a first approach we could reorder our sequences and divide them in two, one part of length $d$ which will have all the errors and the rest $N-d$ . Note that if we do so, for the region of the errors, one can check that if we have in the $\vec{x}'$ a $0$ then in the sequence $\vec{y}'$ there must be a $1$ in the same position, and for the region of the $N-d$ we need that whenever we have a $0$ in the $\vec{x}'$ sequence, there must be a $0$ in the $\vec{y}'$. Indeed it holds also for $\vec{x}''$ and $\vec{y}''$, which in general provides a relation with the weights of each pair of sequences. In figure \ref{CH3:illustration_relation_with_weights}, there is a graphical description to illustrate this situation.\\

\begin{figure}
\centering
\includegraphics[width = \textwidth]{Figures/Esquema-pformas.png}
\caption{Graphical description of the situation in which we we order the modes such that the first $d$ elements correspond to the errors and the rest $N-d$ to the coincidences. This picture illustrate the relation between the weights of the sequences.}
       \label{CH3:illustration_relation_with_weights}
\end{figure}
Explicitly, if we mane $w_x', w_y' , w_x''$ and $w_y''$ to the total weight of the sequences $\vec{x}',\vec{y}',\vec{x}'',\vec{y}''$ respectively,
\begin{equation}
\begin{aligned}
w_x' &= w_1' + w_2',\\
w_y' &= d-w_1' + w_2',\\
w_x'' &= w_1'' + w_2'',\\
w_y'' &= d-w_1'' + w_2''.
\end{aligned}
\label{CH3:Relations_with_the_Weights}
\end{equation} 
Nonetheless, from the way our problem is structured, we know that the transformations we are dealing with ($\mathcal{U}_{\vec{x}\vec{x}'}$ and $\mathcal{V}_{\vec{y}\vec{y}'}$) have an special structure which as we showed in section $3.1.5$ separates the modes of $x$ from the ones of $y$. This implies that the weight of the sequences have to, which is related to the degree of the $p-$form, has to be the same for $\vec{x}'$ and $\vec{x}''$, and therefore implying that
\begin{equation}
w_1' = w_1'' \equiv w_1, \qquad w_2' = w_2'' \equiv w_2
\end{equation} 

where $w_1$ and $w_2$ are restricted to the conditions. In figure \ref{} we illustrate the region we work with

\begin{equation}
\begin{array}{c}
0 \leq w_{1} \leq d \\
0 \leq w_{2}\leq N-d \\
0 \leq w_{1}+w_{2}\leq L\\
0 \leq d-w_{1}+w_{2} \leq L,
\end{array}
\label{CH3:region_to_bound}
\end{equation}


Then, notice that $||\hat{X}_{ij}||$ would reads\footnote{Here we simply count the number of possible sequences that are restricted for the conditions mentioned before. Additionally to this, we use the Haddamard bound for bound the determinant. This bound establishes that if the entries of an $n$ by $n$ matrix $M$, are bounded by a quantity $B$,
\[ 
 \left|\det(M)\right|\leq B^{n}n^{n/2}.
 \]
 For our particular case notice that the transformations $\mathcal{U}$, $\mathcal{V}$ are bounded by $1/\sqrt{N}$}

\begin{equation}
    ||X_{ij}||_{2}^2 \leq \frac{1}{2^L}\sum_{w_1,w_2} {d\choose w_1}^2 {n-d\choose w_2}^2 \left[\frac{2}{N}(w_1+w_2)\right]^{w_1+w_2}
    \left[\frac{2}{N}(d-w_1+w_2)\right]^{d-w_1+w_2}.
    \label{CH3:norm_of_operator_x_i_j}
\end{equation}
 In order to find a bound we suppose that equation \eqref{CH3:norm_of_operator_x_i_j} follows a law of large deviations, therefore we can assert that 
 \begin{equation}
    ||X_{ij}||_{2}^2\leq e^{Nf(w_1,w_2,L,d,N))},
\end{equation}
where $f(w_1,w_2,L,d,N)$ will be given by
\begin{figure}
\centering
\includegraphics[width = 0.6 \textwidth]{Figures/Results_weights.pdf}
\caption{Illustration of the the behaviour of the function $f$ in the region described in \eqref{CH3:region_to_bound},  for values of $N=100$, $d=39$ and $L=40$. As we can see most of the values are positive in the region.}
       \label{CH3:illustration_function_region}
\end{figure}

\begin{figure}
\centering
\includegraphics[width = 0.6\textwidth]{Figures/Results_Weights_3d.pdf}
\caption{Illustration in $3D$ of the the behaviour of the function $f$ in the region described in \eqref{CH3:region_to_bound},  for values of $N=100$, $d=39$ and $L=40$. In this plot we can see clearer that only a small part of the whole region is negative.}
       \label{CH3:illustration_relation_with_weights_3D}
\end{figure}
 \begin{equation}
\begin{split}
    f(w_1,w_2,L,d,N) = 2\frac{d}{N}H_{2}\left(\frac{w_1}{2}\right) &+ 2 \left(1-\frac{d}{N}\right)H_{2}\left(\frac{w_2}{N-d}\right)+\frac{w_1+w_2}{N}\log_2\left(2\frac{w_1+w_2}{N}\right)\\
    & + \frac{d-w_1+w_2}{N}\log_2\left(2\frac{d-w_1+w_2}{N}\right)-\frac{L}{N}.
\end{split}
\end{equation}
Our goal is now study the behaviour of this function in the region described in \eqref{CH3:region_to_bound}, Notice that if the function is negative in the all the region, we can assure that the quantity $||\hat{X}_{ij}||$ will be bounded by a quantity which is exponentially small in $N$ (The size of the system). In figures \ref{CH3:illustration_function_region} and \ref{CH3:illustration_relation_with_weights_3D} we can see the behaviour of the function $f$ is such that over the region, it will be positive. This is, $||\hat{X}_{ij}||$ will be bounded by a quantity which is exponentially large, which is quite the opposite we wanted to proof. However, this approach was quite na\"ive and we never took into account the structure of the $XY$ model. As we will show briefly, to bound this quantity and proof what we want it is needed to consider the structure of the $XY$ model.\\
First to convince us that this quantity is indeed quite small we first do a numerical experiment. We are going to compute and ensemble of determinants in \eqref{CH2:Equation_to_find_bound} for the case of the $XY$ model. To do so, we first generate the transformations $O$ as we described in section $3.1.5$, we take the projection to at the fist $L$ modes and by randomly generating the sequences $\vec{x}',\vec{x}''$ and computing the determinant of the correspondent minor. The results for a particular value of $L$ and $N$ are shown in figure \ref{CH3:Determinant of minors}.

\begin{figure}
\centering
\includegraphics[width = 0.7\textwidth]{Figures/Determinant_minors.png}
\caption{Histogram of the $\log$ of the absolute value of the determinant in \eqref{CH2:Equation_to_find_bound} for the case of the $XY$ model. The parameters here were $N=200$ and $L=50$.}
       \label{CH3:Determinant of minors}
\end{figure}

Even more, if we change $L$ for a given $N$, we could build a surface with the histograms at different length $L$. This is shown in figure 



\begin{figure}
\centering
\includegraphics[width = 0.7\textwidth]{Figures/Determinant_minors_surface.pdf}
\caption{Surface form by the histograms of the $\log$ of the absolute value of the determinant in \eqref{CH2:Equation_to_find_bound} for the case of the $XY$ model. Here the dependence with the size of the subsystem $L$.  The parameters here were $N=200$ and varying from $L=7$ to $90$.}
       \label{CH3:Determinant of minors_surface}
\end{figure}
Having seen these results we then have an insight that indeed $||\hat{X}_{ij}||$ must be quite small. To understand why this is happening, we will find an expression for $O^{T}\Pi_L O$. Notice that the rows in our transformations for the $XY$ are cosine functions, which in terms of the angle $\theta_k$ reads,
\begin{equation}
    u^{k}(x) = \sqrt{\frac{2}{N}}\cos{\theta_k x}.
\end{equation}
Since our interest is to find the an explicit form for the sum of the product of two of these functions, we have than that

\begin{equation}
\sum_{\vec{x}}O_{\vec{x},\vec{x}'}O_{\vec{x},\vec{x}''} \equiv A\rightarrow\quad  A_{i,j}=\sum_{x=-\frac{L-1}{2}}^{\frac{L-1}{2}}u^{i}(x)u^{j}(x).
\end{equation}
with a little of algebra and a property of the sum of cosines\footnote{The exact relation used to proof this is given by  \[\cos\theta_i x\cos\theta_j x = \frac{1}{2}\left(\cos(x(\theta_j-\theta_k))+\cos(x(\theta_j+\theta_k))\right)\]} we can show that
\begin{equation}
   A_{i,j} =\frac{1}{N}D_{L}(\theta_{j}-\theta_{i}),
\end{equation}
where $D_{L}(\theta_{j}-\theta_{i})$ is the Dirichlet kernel given by
\begin{equation}
D_L(x)= \frac{\sin\left(x\frac{L}{2}\right)}{\sin\left(\frac{x}{2}\right)}.
\end{equation}
So in terms of the sequences $\vec{x}',\vec{x}''$, the matrix $O^{T}\Pi_L O$ can be written as
\begin{equation}
    O^{T}\Pi_L O\vert_{\vec{x}',\vec{x}''} = \frac{1}{N}D_{L}\left(\frac{2\pi}{N}(\vec{x}'-\vec{x}'')\right).
    \label{CH3:Dirichlet_for_projection_of_transformation_O}
\end{equation}

Therefore in order to bound the determinant of the minor we could do two things. One is that we could try to find one bound by force, but this technique was proved previously to do not work really well. Or the other is to exploit the fact that the matrix $O^{T}\Pi_L O$ belongs to a particular kind of matrices named Toeplitz matrices. As we show in figure \ref{Matrices_comparison}, this kind of matrix is known to have fixed values over the diagonals, being one kind of sparse matrix.

\begin{figure}[H]
    \begin{subfigure}[b]{0.48\textwidth}
    \centering
  % include first image
  \includegraphics[width=\textwidth]{Figures/Matrix.png}  
  \caption{Plot of the matrix $O^{T}\Pi_L O$, with $N=8000$ and $L=30$}
  \label{Matriz_dirichlet}
    \end{subfigure}
  \hfill 
\begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/Matrix_approx.png}
        \caption{Matrix found by using equation \eqref{CH3:Dirichlet_for_projection_of_transformation_O}, which relate the elements of the matrix and Dirichlet kernel $\frac{1}{N} D_L\left(\frac{2\pi}{N}(\vec{x}'-\vec{x}'')\right)$, with $N=8000$ and $L=30$}
        \label{Matriz_dirichlet_approx}
    \end{subfigure}%
    \caption{Comparison between the two matrices, this illustrates first, the fact that indeed the matrix $O^{T}\Pi_L O$ is a Toeplitz matrix and second, that for the case of the $XY$ model the matrix $O^{T}\Pi_L O$ can be written in terms of the Dirichlet kernel.}
    \label{Matrices_comparison}
\end{figure}

This kind of matrices have been a subject of great study this is because this kind of matrices appear in many physical systems \cite{bottcher_introduction_1999,bump_lie_2013,noauthor_fisher-hartwig_nodate}. It turns out that the computation of this kind of determinants has already been studied and indeed, it this computation is a case of use of the Frobenius-Schur duality theorem\cite{bump_lie_2013}. Particularly, it is possible to use a generalisation of Szeg\"o theorem\cite{szego_grenzwertsatz_1915} provided by Bump and Diaconis \cite{bump_toeplitz_2002}. In this theorem, as in the case of Szeg\"o theorem, it is possible to find an asymptotic expression for the determinant of Toeplitz minors. Astonishingly, the character of the symmetric group ($U(N)$) emerges in this expression.\\
Let $\lambda$ and $\mu$ be partitions of length $\leq N$\cite{bump_lie_2013},
\begin{equation}
D^{\lambda,\mu}_{n-1}(f) = \operatorname{det} (d_{\lambda_i-\mu_j-i+j}) ,
\label{CH3:determinante_szego}
\end{equation}
where $d_i$ are the elements of the Toeplitz matrix. It is not hard to check that indeed the expression in \eqref{CH3:determinante_szego} is the minor in a large Toeplitz matrix\cite{bump_lie_2013}.
\begin{theorem}[Heine, SzegÃ¶, Bump, Diaconis]
Let $f\in L^{1}(\mathbb{T}$ be given, with $f(t)=\sum_{n=-\infty}^{\infty}d_nt^n$, the symbol of the Toeplitz matrix. Let $\lambda$ and $\mu$ be partitions of length $\leq N$. Define a function $\Phi_{n,f}(g)$ on $U(n)$ by $\Phi_{n,f}(g)=\prod_{i=1}^{n} f(t_i)$, where $t_i$ are the eigenvalues of $g\in U(n)$. Then
\begin{equation}
D_{n-1}^{\lambda, \mu}(f)=\int_{\mathrm{U}(n)} \Phi_{n, f}(g) \overline{\chi_{\lambda}(g)} \chi_{\mu}(g) \mathrm{d} g,
\end{equation}
with $\chi_{i}$ the character of $U(n)$\cite{bump_toeplitz_2002,bump_lie_2013}.
\end{theorem}
Note that if $\lambda$ and $\mu$ are trivial, the last expression will become \textit{Heine-Szeg\"o} identity.
With the latter theorem we have then an analytical expression to compute determinant of the Toeplitz minor and find the exact value of \eqref{CH2:Equation_to_find_bound} for the case of the $XY$ model.






